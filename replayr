#!/usr/bin/env python

import threading
import time
from datetime import datetime
import re
import urllib2
import socket
from optparse import OptionParser
# set default socket timeout to 20s as unable to set timeout on urlopen in python 2.4.3
socket.setdefaulttimeout(20)

class ParseError(Exception):
  pass

class ReplayR(object):
  DATE_RE = re.compile(r'\d{2}/\w{3}/\d{4}:\d{2}:\d{2}:\d{2}')
  URL_RE = re.compile(r'(GET|HEAD|POST|PUT) ([^\s]*)')

  DATE_FMT = r'%d/%b/%Y:%H:%M%S'

  def __init__(self, socket_timeout=20, num_threads=15, domain="www.example.com"):
    self._socket_timeout = socket_timeout
    socket.setdefaulttimeout(socket_timeout)
    self.num_threads = num_threads
    self.domain = domain

  def run(self, logpath):
    self.loglines = self._read_lines(logpath)
    self.file_start = self.parse_time(self.loglines[0])
    self.file_end = self.parse_time(self.loglines[-1])
    self.run_start = datetime.now()

    print "Processing %s lines (%s) of logs." % (len(self.loglines), self.file_end - self.file_start)

    for i in range(self.num_threads):
      t = ThreadClass(self, i)
      t.start()

  def _read_lines(self, logpath):
    logfile = None
    try:
      return open(logpath).readlines()
    finally:
      if logfile:
        logfile.close()

  def parse_time(self, line):
    match = self.DATE_RE.search(line)
    if not match:
      raise ParseError("Failed to parse time from line.")

    return datetime.fromtimestamp(
      time.mktime(
        time.strptime(match.group(0), self.DATE_FMT)
      )
    )

  def parse_path(self, line):
    match = self.URL_RE.search(line)
    if not match:
      raise ParseError("Failed to parse request.")
    return match.group(1), match.group(2)

class ThreadClass(threading.Thread):
  def __init__(self, replayr, num):
    super(ThreadClass, self).__init__(name="Thread-%s" % num)

    self._replayr = replayr
    self._num = num

  def run(self):
    while len(self._replayr.loglines) > 0:
      processline = self._replayr.loglines.pop(0)
      try:
        line_time = self._replayr.parse_time(processline)
        request_method, request_path = self._replayr.parse_path(processline)

        if request_method not in ["GET", "HEAD"]:
          print "Skipping %s request." % request_method
        else:
          offset = line_time - self._replayr.file_start
          time_running = datetime.now() - self._replayr.run_start
          if offset > time_running:
            # The request doesn't have to be made yet so sleep until it needs to be
            print '%s Having a nap for %ss' %(self.getName(), offset-time_running)
            time.sleep(time.mktime(offset.timetuple()) - time.mktime(time_running.timetuple()))
            print '%s Processing %s [%s] %ss in, should run at %ss in' %(self.getName(), line_time, request_path, self.time_running(), offset)
          else:
            # The request needs to run now, there is a chance it may be behind as well
            # @todo Only report behind if more than 500ms behind
            print '%s Behind processing %s [%s] %ss in, should run at %ss in' %(self.getName(), line_time, request_path, self.time_running(), offset)

          # Catch 404 errors and ignore as these are fine and part of the running process
          try:
            urllib2.urlopen('http://%s%s' % (self._replayr.domain, request_path))
          except urllib2.HTTPError, e:
            print "Caught HTTP %s Error" % e.code
      except ParseError, e:
        print e.message

  def time_running(self):
    return datetime.now() - self._replayr.run_start

if __name__ == "__main__":
    parser = OptionParser()
    parser.add_option("-t", "--socket-timeout", dest="timeout", default=20, type="int",
                      help="Socket timeout")
    parser.add_option("-n", "--num-threads", dest="threads", default=15, type="int",
                      help="Number of threads to use.")
    parser.add_option("-d", "--domain", dest="domain", default="www.example.com",
                      help="Domain to run requests against.")

    (options, args) = parser.parse_args()
    if not len(args):
        raise Exception("Log file required")

    replayr = ReplayR(socket_timeout=options.timeout, num_threads=options.threads, domain=options.domain)

    # @todo handle multiple files
    replayr.run(args[0])

